{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chardet\n",
    "from pathlib import Path\n",
    "import pyeeg\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worked on after eeg_motor_imagery_nn.ipynb to extract various features and then model. \n",
    "\n",
    "Changes needed:\n",
    "edit 27th July, 2022\n",
    "1. for each of the epochs break into various bands [break into 5 bands alpha, beta...] start calculating the features\n",
    "2. features: psd, attention (alpha band/beta band), frontal assymetery (difference between the left hemisphere and right)\n",
    "3. average of time_series_data (just take the average of epoch)\n",
    "\n",
    "\n",
    "Sources used:\n",
    "https://mne.tools/stable/generated/mne.time_frequency.psd_welch.html (visited: 05/08/2022)\n",
    "https://mne.tools/stable/auto_tutorials/time-freq/20_sensors_time_frequency.html#sphx-glr-auto-tutorials-time-freq-20-sensors-time-frequency-py (visited: 05/08/2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subjects_task(subject, task, run_number_left = 0, run_number_right = 3):\n",
    "    event_id = dict(hands=2, feet=3)\n",
    "    runs = [[3, 7, 11], [4, 8, 12], [5, 9, 13], [6, 10, 14]]   \n",
    "    # runs[0] open and close left or right fist\n",
    "    # runs[1] imagine opening and closing left or right fist\n",
    "    # runs[2] open and close both fists or both feet\n",
    "    # runs[3] imagine opening and closing both fists or both feet\n",
    "\n",
    "    \"\"\"\n",
    "        T0 corresponds to rest\n",
    "        T1 corresponds to onset of motion (real or imagined) of\n",
    "            the left fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "            both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "        T2 corresponds to onset of motion (real or imagined) of\n",
    "            the right fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "            both feet (in runs 5, 6, 9, 10, 13, and 14)\n",
    "    \"\"\"\n",
    "    raw_fnames = mne.datasets.eegbci.load_data(subject, runs[task][run_number_left:run_number_right])\n",
    "    raw = mne.io.concatenate_raws([mne.io.read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "    channel_rename_dict = {'Fc5.':'FC5', 'Fc3.':'FC3', 'Fc1.':'FC1', 'Fcz.':'FCz', \n",
    "                      'Fc2.':'FC2', 'Fc4.':'FC4', 'Fc6.':'FC6', 'C5..':'C5', \n",
    "                      'C3..':'C3', 'C1..':'C1', 'Cz..':'Cz', 'C2..':'C2', \n",
    "                      'C4..':'C4', 'C6..':'C6', 'Cp5.':'CP5', 'Cp3.':'CP3', \n",
    "                      'Cp1.':'CP1', 'Cpz.':'CPz', 'Cp2.':'CP2', 'Cp4.':'CP4', \n",
    "                      'Cp6.':'CP6', 'Fp1.':'Fp1', 'Fpz.':'Fpz', 'Fp2.':'Fp2', \n",
    "                      'Af7.':'AF7', 'Af3.':'AF3', 'Afz.':'AFz', 'Af4.':'AF4', \n",
    "                      'Af8.':'AF8', 'F7..':'F7', 'F5..':'F5', 'F3..':'F3', \n",
    "                      'F1..':'F1', 'Fz..':'Fz', 'F2..':'F2', 'F4..':'F4', \n",
    "                      'F6..':'F6', 'F8..':'F8', 'Ft7.':'FT7', 'Ft8.':'FT8', \n",
    "                      'T7..':'T7', 'T8..':'T8', 'T9..':'T9', 'T10.':'T10', \n",
    "                      'Tp7.':'TP7', 'Tp8.':'TP8', 'P7..':'P7', 'P5..':'P5', \n",
    "                      'P3..':'P3', 'P1..':'P1', 'Pz..':'Pz', 'P2..':'P2', \n",
    "                      'P4..':'P4', 'P6..':'P6', 'P8..':'P8', 'Po7.':'PO7', \n",
    "                      'Po3.':'PO3', 'Poz.':'POz', 'Po4.':'PO4', 'Po8.':'PO8', \n",
    "                      'O1..':'O1', 'Oz..':'Oz', 'O2..':'O2', 'Iz..':'Iz'}\n",
    "    raw.rename_channels(channel_rename_dict)\n",
    "    montage = mne.channels.make_standard_montage('standard_1005')\n",
    "    raw.set_montage(montage)\n",
    "    events, _ = mne.events_from_annotations(raw, event_id=dict(T0=1, T1=2, T2=3))\n",
    "    return raw, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_mean(data, fs, plotting = 0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : is 1d list/np.array\n",
    "        of the signal\n",
    "    fs : int\n",
    "        sampling frequency\n",
    "    plotting : int | 0 or 1\n",
    "        plots the eeg band values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    eeg_band_fft : dict \n",
    "        mean of power of signal in that band\n",
    "    \"\"\"\n",
    "    # data is 1d\n",
    "    # Get real amplitudes of FFT (only in postive frequencies)\n",
    "    fft_vals = np.absolute(np.fft.rfft(data))\n",
    "    # Get frequencies for amplitudes in Hz\n",
    "    fft_freq = np.fft.rfftfreq(len(data), 1.0/fs)\n",
    "    # print(fft_vals.shape, fft_freq.shape)\n",
    "    \n",
    "    # Define EEG bands\n",
    "    eeg_bands = {'Delta': (0, 4),\n",
    "                 'Theta': (4, 8),\n",
    "                 'Alpha': (8, 12),\n",
    "                 'Beta': (12, 30),\n",
    "                 'Gamma': (30, 45)}\n",
    "\n",
    "    # Take the mean of the fft amplitude for each EEG band\n",
    "    # TODO: doubt should I take mean of this or not\n",
    "    eeg_band_fft = dict()\n",
    "    for band in eeg_bands:  \n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & \n",
    "                           (fft_freq <= eeg_bands[band][1]))[0]\n",
    "        eeg_band_fft[band] = np.mean(fft_vals[freq_ix])\n",
    "        # eeg_band_fft[band] = fft_vals[freq_ix]\n",
    "    \n",
    "    # print(\"PRINTING EEG_BAND_FFT\", eeg_band_fft)\n",
    "    # Plot the data (using pandas here cause it's easy)\n",
    "    if plotting == 1:\n",
    "        df = pd.DataFrame(columns=['band', 'val'])\n",
    "        df['band'] = eeg_bands.keys()\n",
    "        df['val'] = [eeg_band_fft[band] for band in eeg_bands]\n",
    "        for band in eeg_bands:\n",
    "            print(eeg_band_fft[band])\n",
    "        ax = df.plot.bar(x='band', y='val', legend=False)\n",
    "        ax.set_xlabel(\"EEG band\")\n",
    "        ax.set_ylabel(\"Mean band Amplitude\")\n",
    "    return eeg_band_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw_data_2d_extract_features(raw, events, participant_id, df_eeg_features, plotting=0):\n",
    "    # edit 27th July, 2022\n",
    "    # for each of the epochs break into various bands [break into 5 bands alpha, beta...]\n",
    "    # start calculating the features\n",
    "    # features: psd, attention (alpha band/beta band), frontal assymetery (difference between the left hemisphere and right)\n",
    "    # average of time_series_data (just take the average of epoch)\n",
    "    raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "    event_id = dict(hands=2, feet=3)\n",
    "    tmin, tmax = -1., 4.\n",
    "    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False)\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                baseline=None, preload=True)\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "    i = 0\n",
    "    for epoch in epochs_train:\n",
    "        \n",
    "        # bands\n",
    "        eeg_band_fft = fft_mean(epoch, epochs.info['sfreq'])\n",
    "        # print(eeg_band_fft)\n",
    "        eeg_band_fft[\"label\"] = labels[i]\n",
    "        eeg_band_fft[\"participant_id\"] = participant_id\n",
    "        \n",
    "        # epoch average\n",
    "        epoch_avg = np.average(epoch)\n",
    "        eeg_band_fft[\"epoch_avg\"] = epoch_avg\n",
    "        \n",
    "        # psd\n",
    "        # TODO: DOUBT how to add this to dataset\n",
    "        # what should n_fft be: 161, 100, or 99\n",
    "        kwargs = dict(fmin=2, fmax=40)\n",
    "        psds_welch_mean, freqs_mean = mne.time_frequency.psd_welch(epochs_train[i], n_fft=99, average='mean', **kwargs)\n",
    "        psds_welch_median, freqs_median = mne.time_frequency.psd_welch(epochs_train[i], n_fft=99, average='median', **kwargs)\n",
    "        \n",
    "        \n",
    "        if plotting == 1:\n",
    "            # We will only plot the PSD for a single sensor in the first epoch.\n",
    "            ch_name = 'Fp1'\n",
    "            ch_idx = epochs.info['ch_names'].index(ch_name)\n",
    "            print(\"PRINTING CH_IDX\", ch_idx)\n",
    "            epo_idx = 0\n",
    "            _, ax = plt.subplots()\n",
    "            ax.plot(freqs_mean, psds_welch_mean[epo_idx, ch_idx, :], color='k',\n",
    "                    ls='-', label='mean of segments')\n",
    "            ax.plot(freqs_median, psds_welch_median[epo_idx, ch_idx, :], color='k',\n",
    "                    ls='--', label='median of segments')\n",
    "\n",
    "            ax.set(title='Welch PSD ({}, Epoch {})'.format(ch_name, epo_idx),\n",
    "                   xlabel='Frequency (Hz)', ylabel='Power Spectral Density (dB)')\n",
    "            ax.legend(loc='upper right')\n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "        df_eeg_features = df_eeg_features.append(eeg_band_fft, ignore_index=True)\n",
    "        i += 1\n",
    "    return df_eeg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_data_extract_features(num_of_participants = 109):\n",
    "    training_data_of_participants = []\n",
    "    labels_of_participants = []\n",
    "    df_eeg_features = pd.DataFrame()\n",
    "    for i in range(1, num_of_participants + 1):\n",
    "        subject_raw, subject_events = load_subjects_task(i, 0)\n",
    "        df_eeg_features = preprocess_raw_data_2d_extract_features(subject_raw, subject_events, i, df_eeg_features, plotting = 0)\n",
    "    return df_eeg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bands = load_participant_data_extract_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bands[\"label\"] = df_bands[\"label\"].astype('int')\n",
    "df_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bands_2 = df_bands.drop([\"participant_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bands_2[df_bands_2.columns.difference([\"label\"])]\n",
    "y = df_bands_2[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=4, stratify=y)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(list(predictions))\n",
    "print(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_the_model = model.score(X_test, y_test)\n",
    "print('model score: {}'.format(score_of_the_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "score_of_the_model = clf.score(X_test, y_test)\n",
    "print('model score: {}'.format(score_of_the_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
